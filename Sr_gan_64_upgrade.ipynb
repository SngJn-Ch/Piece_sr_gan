{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i9CQo6Lfwd1z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dgGy3JOzw23u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, Flatten, Input, MaxPooling2D, LeakyReLU, BatchNormalization, PReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "\n",
        "# from PIL import Image\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "import cv2\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.pylabtools import figsize\n",
        "from glob import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import tarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NR3lguu3xYCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e3dbf1-3094-40f9-cbd3-c0e7c6e45484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "glvEAarGJl_S"
      },
      "outputs": [],
      "source": [
        "# !unzip -q /content/drive/MyDrive/every_Gan/grayscale_data/mirflickr25k.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvf /content/drive/MyDrive/Coding/Data/ILSVRC2013_DET_train.tar"
      ],
      "metadata": {
        "id": "toKnGFTMv4Du"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2YhsEjdgQFj8"
      },
      "outputs": [],
      "source": [
        "# !mkdir data\n",
        "# !mv /content/mirflickr/*.jpg data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CuPNuqkfQUrw"
      },
      "outputs": [],
      "source": [
        "# img_path = glob(\"data/*.JPEG\")\n",
        "# print(len(img_path))\n",
        "# train_path = \"data\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def size_check(img_path):\n",
        "  counter = 0\n",
        "  for ii in img_path:\n",
        "    image_opener = cv2.imread(ii)\n",
        "    if image_opener.shape[0] < 256 and image_opener.shape[1] < 256:\n",
        "      os.remove(ii)\n",
        "  "
      ],
      "metadata": {
        "id": "SvxEJw3qPPC7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYl9CxKHWTvG"
      },
      "source": [
        "흑백사진 조심하기 2트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "TJiA9cAqQuJb"
      },
      "outputs": [],
      "source": [
        "image_size = (32,32,3)\n",
        "H = image_size[0]\n",
        "W = image_size[1]\n",
        "C = image_size[2]\n",
        "\n",
        "target_size = (64,64,3)\n",
        "T_H = target_size[0]\n",
        "T_W = target_size[1]\n",
        "T_C = target_size[2]\n",
        "\n",
        "batch_size = 8\n",
        "epochs = 150\n",
        "sample_every = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "viMy1UInrA3w"
      },
      "outputs": [],
      "source": [
        "def g_layer_block(kernel_size, units, strides, x):\n",
        "\n",
        "  x = Conv2D(filters = units, kernel_size= kernel_size, strides = strides, padding = \"same\")(x)\n",
        "  \n",
        "  x = BatchNormalization(momentum = 0.5)(x)\n",
        "  x = PReLU(shared_axes = [1,2])(x)\n",
        "  x = Conv2D(filters = units, kernel_size= kernel_size, strides = strides, padding = \"same\")(x)\n",
        "  \n",
        "  \n",
        "  x = BatchNormalization()(x)\n",
        "  \n",
        "  return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ItE7v4P935W6"
      },
      "outputs": [],
      "source": [
        "def g_layer_block_2(kernel_size, units, strides, x, scale):\n",
        "  x = Conv2D(filters = units, kernel_size= kernel_size, strides = strides, padding = \"same\")(x)\n",
        "  x = tf.nn.depth_to_space(x,scale)\n",
        "  x = PReLU(shared_axes = [1,2])(x)\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "vbb_b41jiGZQ"
      },
      "outputs": [],
      "source": [
        "def g_layer_block_3(x, connect_x):\n",
        "  x = g_layer_block(kernel_size=3, units = H, strides = 1, x= x)\n",
        "  x = tf.keras.layers.add([connect_x, x])\n",
        "  new_connect_x = x\n",
        "\n",
        "  return x, new_connect_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "-K0BnDglQ6vR"
      },
      "outputs": [],
      "source": [
        "def build_generator(img_size):\n",
        "  i = Input(shape = img_size)\n",
        "  x = Conv2D(filters = H, kernel_size = 9, strides = 1, padding = \"same\")(i)\n",
        "  x = PReLU(shared_axes = [1,2])(x)\n",
        "\n",
        "  connect_x = x\n",
        "  connect_x_2 = connect_x\n",
        "\n",
        "  num_residual = 16\n",
        "  for j in range(num_residual):\n",
        "    x, connect_x = g_layer_block_3(x, connect_x= connect_x)\n",
        "  \n",
        "  \n",
        "  x = Conv2D(kernel_size=3, filters = H, strides = 1, padding = \"same\")(x)\n",
        "  x = BatchNormalization(momentum = 0.5)(x)\n",
        "  x = tf.keras.layers.add([connect_x_2,x])\n",
        "\n",
        "  x = g_layer_block_2(kernel_size=3, units= H*4, strides= 1, x= x, scale = 2)\n",
        "\n",
        "  # x = g_layer_block_2(kernel_size=3, units= H*4, strides= 1, x= x, scale = 2)\n",
        "  # x = Conv2D(filters= 3, kernel_size=9, strides = 1, padding = \"same\" )(x)\n",
        "\n",
        "  x = Conv2D(filters= 3, kernel_size=9, strides = 1, padding = \"same\", activation = \"tanh\")(x)\n",
        "\n",
        "  model = Model(inputs = i, outputs = x)\n",
        "  return model\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "IsIw8_v_aCTw"
      },
      "outputs": [],
      "source": [
        "def d_layer_block(kernel_size,units,strides,x):\n",
        "  x = Conv2D(filters = units, kernel_size= kernel_size, strides = strides, padding = \"same\")(x)\n",
        "  x = BatchNormalization(momentum=0.8)(x)\n",
        "  x = LeakyReLU()(x)\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "5om6GTl6JwBA"
      },
      "outputs": [],
      "source": [
        "def build_discriminator(img_size):\n",
        "  i = Input(shape = img_size)\n",
        "  x = Conv2D(filters=H, kernel_size=3, strides = 1, activation= LeakyReLU())(i)\n",
        "  x = d_layer_block(3,H,2,x)\n",
        "  x = d_layer_block(3,H*2,1,x)\n",
        "  x = d_layer_block(3,H*2,2,x)\n",
        "  x = d_layer_block(3,H*4,1,x)\n",
        "  x = d_layer_block(3,H*4,2,x)\n",
        "  x = d_layer_block(3,H*8,1,x)\n",
        "  x = d_layer_block(3,H*8,2,x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(H*16)(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "  model = Model(inputs = i, outputs = x)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "tLGMpjHE5lP6"
      },
      "outputs": [],
      "source": [
        "discriminator = build_discriminator(img_size=(T_H,T_W,T_C))\n",
        "\n",
        "generator = build_generator(img_size = (H,W,C))\n",
        "\n",
        "z = Input(shape = (H,W,C))\n",
        "\n",
        "sample_img= generator(z, training = False)\n",
        "\n",
        "fake_pre = discriminator(sample_img, training = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL3xvihf9lxV",
        "outputId": "b698dbec-4aa7-4763-bb5c-b0db28dacce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 32, 32, 32)   7808        ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " p_re_lu_18 (PReLU)             (None, 32, 32, 32)   32          ['conv2d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_18[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 32, 32, 32)  128         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_19 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_19[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 32, 32, 32)  128         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 32, 32, 32)   0           ['p_re_lu_18[0][0]',             \n",
            "                                                                  'batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 32, 32, 32)   9248        ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 32, 32, 32)  128         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_20 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_20[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 32, 32, 32)  128         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 32, 32, 32)   0           ['add_17[0][0]',                 \n",
            "                                                                  'batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 32, 32, 32)   9248        ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 32, 32, 32)  128         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_21 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_21[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 32, 32, 32)  128         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 32, 32, 32)   0           ['add_18[0][0]',                 \n",
            "                                                                  'batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 32, 32, 32)   9248        ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 32, 32, 32)  128         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_22 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_22[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 32, 32, 32)  128         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 32, 32, 32)   0           ['add_19[0][0]',                 \n",
            "                                                                  'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 32, 32, 32)   9248        ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 32, 32, 32)  128         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_23 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_23[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 32, 32, 32)  128         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 32, 32, 32)   0           ['add_20[0][0]',                 \n",
            "                                                                  'batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 32, 32, 32)   9248        ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 32, 32, 32)  128         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_24 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_24[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 32, 32, 32)  128         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 32, 32, 32)   0           ['add_21[0][0]',                 \n",
            "                                                                  'batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 32, 32, 32)   9248        ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 32, 32, 32)  128         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_25 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_25[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 32, 32, 32)  128         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 32, 32, 32)   0           ['add_22[0][0]',                 \n",
            "                                                                  'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 32, 32, 32)   9248        ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 32, 32, 32)  128         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_26 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_26[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 32, 32, 32)  128         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 32, 32, 32)   0           ['add_23[0][0]',                 \n",
            "                                                                  'batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 32, 32, 32)   9248        ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 32, 32, 32)  128         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_27 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_27[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 32, 32, 32)  128         ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 32, 32, 32)   0           ['add_24[0][0]',                 \n",
            "                                                                  'batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 32, 32, 32)   9248        ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 32, 32, 32)  128         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_28 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_28[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 32, 32, 32)  128         ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 32, 32, 32)   0           ['add_25[0][0]',                 \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 32, 32, 32)   9248        ['add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 32, 32, 32)  128         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_29 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_29[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 32, 32, 32)  128         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 32, 32, 32)   0           ['add_26[0][0]',                 \n",
            "                                                                  'batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 32, 32, 32)   9248        ['add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 32, 32, 32)  128         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_30 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_30[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 32, 32, 32)  128         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 32, 32, 32)   0           ['add_27[0][0]',                 \n",
            "                                                                  'batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 32, 32, 32)   9248        ['add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 32, 32, 32)  128         ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_31 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_31[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 32, 32, 32)  128         ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 32, 32, 32)   0           ['add_28[0][0]',                 \n",
            "                                                                  'batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 32, 32, 32)   9248        ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 32, 32, 32)  128         ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_32 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_32[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 32, 32, 32)  128         ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_30 (Add)                   (None, 32, 32, 32)   0           ['add_29[0][0]',                 \n",
            "                                                                  'batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 32, 32, 32)   9248        ['add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 32, 32, 32)  128         ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_33 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_33[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 32, 32, 32)  128         ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_31 (Add)                   (None, 32, 32, 32)   0           ['add_30[0][0]',                 \n",
            "                                                                  'batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 32, 32, 32)   9248        ['add_31[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 32, 32, 32)  128         ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " p_re_lu_34 (PReLU)             (None, 32, 32, 32)   32          ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 32, 32, 32)   9248        ['p_re_lu_34[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 32, 32, 32)  128         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_32 (Add)                   (None, 32, 32, 32)   0           ['add_31[0][0]',                 \n",
            "                                                                  'batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 32, 32, 32)   9248        ['add_32[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 32, 32, 32)  128         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_33 (Add)                   (None, 32, 32, 32)   0           ['p_re_lu_18[0][0]',             \n",
            "                                                                  'batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 32, 32, 128)  36992       ['add_33[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.nn.depth_to_space_1 (TFOpLa  (None, 64, 64, 32)  0           ['conv2d_86[0][0]']              \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " p_re_lu_35 (PReLU)             (None, 64, 64, 32)   32          ['tf.nn.depth_to_space_1[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 64, 64, 3)    7779        ['p_re_lu_35[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 362,563\n",
            "Trainable params: 360,451\n",
            "Non-trainable params: 2,112\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBl_gcryhqVP"
      },
      "source": [
        "Pretrained model -> VGG19_model -> perceptual_model? -> content loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "dgSk09bThdi-"
      },
      "outputs": [],
      "source": [
        "vgg = VGG19(include_top= False, weights = \"imagenet\", input_shape = (T_H, T_W, T_C))\n",
        "# vgg = VGG19(include_top= False, weights = \"imagenet\", input_shape = (None, T_W, T_C))\n",
        "img = Input(shape = (T_H, T_W, T_C))\n",
        "\n",
        "VGG19_model = Model(inputs= vgg.input, outputs = vgg.layers[10].output)\n",
        "\n",
        "VGG19_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YhvVy1_jqSB",
        "outputId": "d9821490-51a9-4f46-d8b8-3b1363e2faab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,325,568\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,325,568\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "VGG19_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Ksu8OlhQf3wV"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/Coding/image_result/Pieced_final_sr/\"\n",
        "if not os.path.exists(file_path):\n",
        "  os.makedirs(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0mosBRNIf6O9"
      },
      "outputs": [],
      "source": [
        "check_path = \"/content/drive/MyDrive/Coding/check_point/Pieced_final_sr\"\n",
        "if not os.path.exists(check_path):\n",
        "  os.makedirs(check_path)\n",
        "check_point = tf.train.Checkpoint(generator = generator, discriminator = discriminator)\n",
        "check_point_manager = tf.train.CheckpointManager(checkpoint=check_point, directory= check_path, max_to_keep= 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6G4GoUNgH52",
        "outputId": "0f915b2b-c681-4bed-9e6e-577173b66b1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f817bc7e290>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "check_point.restore(check_point_manager.latest_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "XJxjZRdjqtx2"
      },
      "outputs": [],
      "source": [
        "def image_to_numpy(batch_size, batch, img_path):\n",
        "\n",
        "  N_minibatch = 256/T_H\n",
        "  \n",
        "  batch_np_64 = np.zeros((1, H, W, C))\n",
        "  batch_np_128 = np.zeros((1, T_H, T_W, T_C))\n",
        "\n",
        "  for img_in_path in img_path[batch:batch + batch_size]:\n",
        "    image_open = cv2.imread(img_in_path)\n",
        "    image_open = cv2.cvtColor(image_open, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image_128, image_64 = minibatch_generator(image_open)\n",
        "\n",
        "    batch_np_64 = np.append(batch_np_64, image_64, axis = 0)\n",
        "    batch_np_128 = np.append(batch_np_128, image_128, axis = 0)\n",
        "\n",
        "  batch_np_64 = np.delete(batch_np_64, 0, axis = 0)\n",
        "  batch_np_128 = np.delete(batch_np_128, 0, axis = 0)\n",
        "\n",
        "  batch_np_64 = ((batch_np_64/255.0)-0.5)*2\n",
        "  batch_np_128 = ((batch_np_128/255.0)-0.5)*2\n",
        "\n",
        "  return batch_np_64, batch_np_128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def minibatch_generator(image_open):\n",
        "    image_256 = cv2.resize(image_open, (256,256))\n",
        "\n",
        "    N_minibatch = 256/T_H\n",
        "    minibatch_128 = np.zeros((1, T_H, T_W, 3))\n",
        "    minibatch_64 = np.zeros((1, H,W,3))\n",
        "\n",
        "    for i in range(int(N_minibatch)):\n",
        "      for j in range(int(N_minibatch)):\n",
        "\n",
        "        mini_mini_batch_128 = image_256[i*T_H:(i+1)*T_H, j*T_W:(j+1)*T_W, 0:3]\n",
        "        mini_mini_batch_64 = cv2.resize(mini_mini_batch_128, (H,W))\n",
        "\n",
        "        mini_mini_batch_128 = np.expand_dims(mini_mini_batch_128, axis = 0)\n",
        "        minibatch_128 = np.append(minibatch_128, mini_mini_batch_128, axis = 0)\n",
        "\n",
        "        mini_mini_batch_64 = np.expand_dims(mini_mini_batch_64, axis = 0)\n",
        "        minibatch_64 = np.append(minibatch_64, mini_mini_batch_64, axis = 0)\n",
        "\n",
        "    minibatch_128 = np.delete(minibatch_128, 0, axis = 0)\n",
        "    minibatch_64 = np.delete(minibatch_64, 0, axis = 0)\n",
        "\n",
        "    return minibatch_128, minibatch_64"
      ],
      "metadata": {
        "id": "Ihss8P_zUGkL"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_result(epoch, img_path):\n",
        "    epoch = epoch\n",
        "    original_size = 256\n",
        "    input_image_size = 32\n",
        "    image_size = 64\n",
        "\n",
        "    rows = int(original_size/image_size)\n",
        "    cols = 3\n",
        "\n",
        "    fig, ax = plt.subplots(rows,cols, figsize = (20,40))\n",
        "    # fig.tight_layout()\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    rand_index = np.random.choice(len(img_path))\n",
        "    img_open = cv2.imread(img_path[rand_index])\n",
        "    real_img = cv2.cvtColor(img_open, cv2.COLOR_BGR2RGB)\n",
        "    if original_size != 512:\n",
        "      real_img = cv2.resize(real_img, (original_size, original_size))\n",
        "      \n",
        "    real_img = real_img/255.0\n",
        "\n",
        "    cropped_images = minibatch_generator_1(real_img, input_image_size)\n",
        "\n",
        "    # Remember that the input is from (-1,1)\n",
        "    cropped_images = (cropped_images-0.5)*2\n",
        "\n",
        "    \n",
        "    start_Index = 0\n",
        "    end_Index = 0\n",
        "    add_Index = 0\n",
        "\n",
        "    for Number_of_images in range(rows):\n",
        "\n",
        "        blank_image_fake = np.zeros(((Number_of_images +1)*image_size,(Number_of_images +1)*image_size,3))\n",
        "\n",
        "        start_Index += (Number_of_images)**2\n",
        "        add_Index = (Number_of_images + 1)**2\n",
        "        end_Index = start_Index + add_Index\n",
        "\n",
        "\n",
        "        image_pieces = cropped_images[start_Index:end_Index, 0:image_size, 0:image_size, 0:3]\n",
        "        \n",
        "        # print(f\"index counter : {start_Index}  end_index : {end_Index}   number_of images : {Number_of_images}\")        \n",
        "\n",
        "        counter = 0\n",
        "        for image_row in range(0,Number_of_images + 1,1):\n",
        "            for image_column in range(0,Number_of_images + 1,1):\n",
        "\n",
        "              fake_img = generator(image_pieces, training = False)\n",
        "\n",
        "              # Remember that the output is (-1,1), change it to (0,1) for plotting\n",
        "              fake_img = (fake_img + 1)/2\n",
        "\n",
        "              \n",
        "              blank_image_fake[image_row*image_size:(image_row+1)*image_size, image_column*image_size:(image_column+1)*image_size, 0:3] = fake_img[counter]\n",
        "              counter += 1\n",
        "\n",
        "        plot_image = cv2.imread(img_path[rand_index])\n",
        "        plot_image = cv2.resize(plot_image, ((Number_of_images +1)*image_size,(Number_of_images +1)*image_size))\n",
        "        plot_image = cv2.cvtColor(plot_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        input_image = cv2.resize(plot_image,((Number_of_images +1)*input_image_size,(Number_of_images +1)*input_image_size))\n",
        "        \n",
        "\n",
        "        complete_fake_img = (blank_image_fake).astype(np.float32)\n",
        "        plot_image = (plot_image/255.0).astype(np.float32)\n",
        "        input_image = (input_image/255.0).astype(np.float32)\n",
        "        \n",
        "      \n",
        "\n",
        "        ax[Number_of_images][0].imshow(input_image)\n",
        "        ax[Number_of_images][1].imshow(complete_fake_img)\n",
        "        ax[Number_of_images][2].imshow(plot_image)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "    while True:\n",
        "      file_name = file_path + f\"/%d.png\" %epoch\n",
        "      \n",
        "      if not os.path.exists(file_name):\n",
        "        break     \n",
        "      epoch += 2\n",
        "\n",
        "    plt.savefig(file_name)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "7br-iDvcbe0Y"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "OBIW2BJtgKpZ"
      },
      "outputs": [],
      "source": [
        "discriminator_losses = tf.keras.losses.BinaryCrossentropy()\n",
        "generator_losses = tf.keras.losses.BinaryCrossentropy()\n",
        "content_losses = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "learning_rate = PiecewiseConstantDecay(boundaries = [100000], values = [1e-4, 1e-5])\n",
        "\n",
        "gen_optimizer = Adam(learning_rate = learning_rate)\n",
        "dis_optimizer = Adam(learning_rate = learning_rate)\n",
        "\n",
        "\n",
        "def content_loss(real_imgs, fake_imgs):\n",
        "\n",
        "  # change image rgb range from (-1,1) to (0,1)\n",
        "  real_imgs = (real_imgs + 1)/2\n",
        "  fake_imgs = (fake_imgs + 1)/2\n",
        "\n",
        "  real_imgs = preprocess_input(real_imgs)\n",
        "  fake_imgs = preprocess_input(fake_imgs)\n",
        "\n",
        "  how_real_classified = VGG19_model(real_imgs)\n",
        "  how_fake_classified = VGG19_model(fake_imgs)\n",
        "\n",
        "  vgg_loss = content_losses(how_real_classified, how_fake_classified)\n",
        "  \n",
        "\n",
        "  return vgg_loss\n",
        "  \n",
        "\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = discriminator_losses(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = discriminator_losses(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    \n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "\n",
        "    fake_loss = generator_losses(tf.ones_like(fake_output), fake_output)\n",
        "    \n",
        "    return fake_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_img_path = glob(\"/content/extracted_tar/n01503061/*.JPEG\")\n",
        "# plot_result(99999, sample_img_path)"
      ],
      "metadata": {
        "id": "q39lnhhE-4Ot"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def minibatch_generator_1(image_open, image_size):\n",
        "    original_size = 256\n",
        "    max_pieces = int(original_size/image_size)\n",
        "\n",
        "    N_minibatch = original_size/H\n",
        "    minibatch_128 = np.zeros((1, H, W, 3))\n",
        "\n",
        "    for N_pieces in range(max_pieces):\n",
        "      full_image_size = image_size*(N_pieces + 1)\n",
        "      image_open_resized = cv2.resize(image_open, (full_image_size, full_image_size))\n",
        "\n",
        "      for i in range(N_pieces + 1):\n",
        "        for j in range(N_pieces + 1):\n",
        "          mini_mini_batch_128 = image_open_resized[i*image_size:(i+1)*image_size, j*image_size:(j+1)*image_size, 0:3]\n",
        "          mini_mini_batch_128 = np.expand_dims(mini_mini_batch_128, axis = 0)\n",
        "          minibatch_128 = np.append(minibatch_128, mini_mini_batch_128, axis = 0)\n",
        "\n",
        "    minibatch_128 = np.delete(minibatch_128, 0, axis = 0)\n",
        "\n",
        "    return minibatch_128"
      ],
      "metadata": {
        "id": "bZf9HyIdb3i2"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "o9VNazJxiqs9"
      },
      "outputs": [],
      "source": [
        "def train_step(real_imgs, lr_imgs):\n",
        "  \n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
        "\n",
        "    fake_hr_imgs = generator(lr_imgs, training = True)\n",
        "\n",
        "    real_outputs = discriminator(real_imgs, training = True)\n",
        "    fake_outputs = discriminator(fake_hr_imgs, training = True)\n",
        "\n",
        "    d_loss = discriminator_loss(real_output = real_outputs, fake_output = fake_outputs)\n",
        "    g_loss = generator_loss(fake_output = fake_outputs)\n",
        "    c_loss = content_loss(real_imgs = real_imgs, fake_imgs=fake_hr_imgs)\n",
        "\n",
        "    SR_loss = c_loss + 0.001*g_loss\n",
        "    \n",
        "    \n",
        "    g_gradient = gen_tape.gradient(SR_loss, generator.trainable_variables)\n",
        "    d_gradient = dis_tape.gradient(d_loss, discriminator.trainable_variables)\n",
        "\n",
        "    gen_optimizer.apply_gradients(zip(g_gradient, generator.trainable_variables))\n",
        "    dis_optimizer.apply_gradients(zip(d_gradient, discriminator.trainable_variables))\n",
        "\n",
        "    return d_loss, SR_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONkN2vbUTzaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfb7f8a-8173-4e34-d3fb-4f119061b770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 355/355 [03:50<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0/150   d_loss : 0.06091   g_loss : 1.95870 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 355/355 [03:49<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.56it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:47<00:00,  1.56it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 10/150   d_loss : 0.00368   g_loss : 1.69171 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.55it/s]\n",
            "100%|██████████| 355/355 [03:48<00:00,  1.56it/s]\n",
            " 29%|██▊       | 102/355 [01:05<02:40,  1.57it/s]"
          ]
        }
      ],
      "source": [
        "d_losses = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "g_losses = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "import tarfile\n",
        "import random\n",
        "d_losses = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "g_losses = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "sample_path = glob(\"/content/drive/MyDrive/every_Gan/imagenet_2013/*.tar\")\n",
        "np.random.shuffle(sample_path)\n",
        "file_number = 0\n",
        "for tar in sample_path:\n",
        "\n",
        "  file_number += 1\n",
        "\n",
        "  result_file_with_number = file_path + \"file_sample_\" + str(file_number)\n",
        "  file_name = \"/content/extracted_tar\"\n",
        "\n",
        "  if not os.path.exists(file_name):\n",
        "    os.makedirs(file_name)\n",
        "\n",
        "  \n",
        "  \n",
        "  my_tar = tarfile.open(tar)\n",
        "  my_tar.extractall(file_name)\n",
        "  my_tar.close()\n",
        "\n",
        "  img_p_1 = glob(file_name + \"/*/*.JPEG\")\n",
        "  img_p_2 = glob(file_name + \"/*.JPEG\")\n",
        "\n",
        "  img_path = img_p_1 + img_p_2\n",
        "\n",
        "  size_check(img_path)\n",
        "\n",
        "  img_p_1 = glob(file_name + \"/*/*.JPEG\")\n",
        "  img_p_2 = glob(file_name + \"/*.JPEG\")\n",
        "\n",
        "  img_path = img_p_1 + img_p_2\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for batch in tqdm(range(0,len(img_path) - 1, batch_size)):\n",
        "      \n",
        "      # image to numpy change image into numpy and return (-1,1) range rgb data\n",
        "      image_64, image_128 = image_to_numpy(batch_size = batch_size, batch = batch, img_path = img_path)\n",
        "\n",
        "\n",
        "      d_loss, SR_loss = train_step(real_imgs = image_128, lr_imgs = image_64)\n",
        "\n",
        "      d_losses.update_state(d_loss)\n",
        "      g_losses.update_state(SR_loss)\n",
        "      \n",
        "    if epoch % sample_every == 0:\n",
        "      print(f\"epoch : {epoch}/{epochs}   d_loss : {d_losses.result():0.5f}   g_loss : {g_losses.result():0.5f} \")\n",
        "      # sample_images(epoch, img_path)\n",
        "      plot_result(epoch, img_path)\n",
        "      # check_point.step.assign_add(1)\n",
        "      \n",
        "      d_losses.reset_states()\n",
        "      g_losses.reset_states()\n",
        "\n",
        "      # check_point_manager.save()\n",
        "  shutil.rmtree(file_name, ignore_errors = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}